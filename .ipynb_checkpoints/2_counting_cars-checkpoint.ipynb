{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "278e0482",
   "metadata": {},
   "source": [
    "# Ex 1.2 Counting Cars\n",
    "This task focuses on developing a computer vision application for counting the number of cars going from the city's downtown to the city centre in peak hours. It will be a progression to task 1.1 which uses the OpenCV library, and is based on frame differencing and background subtraction techniques. The project focuses on detecting cars that are in the \"Main street\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "009600ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9868a9",
   "metadata": {},
   "source": [
    "The code will follow task 1.1's algorithm, tweaked to count cars.<br>The background subtractor MOG2 will be used with the same parameters as task 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111f515d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully opened video 1.\n",
      "Successfully opened video 2.\n"
     ]
    }
   ],
   "source": [
    "# creating an instance of Gaussian Mixture-based background subtraction\n",
    "background_sub = cv2.createBackgroundSubtractorMOG2( history = 500,\n",
    "                                                     varThreshold = 50,\n",
    "                                                     detectShadows = True )\n",
    "\n",
    "# loading the video file\n",
    "vid_path1, vid_path2 = \"media/Traffic_Laramie_1.mp4\", \"media/Traffic_Laramie_2.mp4\"\n",
    "capture1 = cv2.VideoCapture(vid_path1)\n",
    "capture2 = cv2.VideoCapture(vid_path2)\n",
    "\n",
    "# checking if video 1 is opened successfully\n",
    "if not capture1.isOpened(): print(\"Error: Could not open video 1.\")\n",
    "else: print(\"Successfully opened video 1.\")\n",
    "# checking if video 2 is opened successfully\n",
    "if not capture2.isOpened(): print(\"Error: Could not open video 2.\")\n",
    "else: print(\"Successfully opened video 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655db5ad",
   "metadata": {},
   "source": [
    "The algorithm detects and counts vehicles moving towards the city center. The Region of Interest (ROI) is applied to focus detection on the main street. ```cv2.dilate()``` and ```cv2.erode()``` are used to ensure that the detected vehicles are not fragmented whilst removing noise.\n",
    "\n",
    "Moving objects are then detected, non-vehicle objects are filtered out based on the aspect ratio and contour area. Vehicles are tracked using their center coordinates to ensure that they are counted only once when crossing into the city center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4490a571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car detected, Total: 1\n",
      "Car detected, Total: 2\n",
      "Car detected, Total: 3\n",
      "Car detected, Total: 4\n",
      "Car detected, Total: 5\n",
      "Car detected, Total: 6\n"
     ]
    }
   ],
   "source": [
    "# defining main street region of interest (ROI)\n",
    "roi_top_left = (0, 250)\n",
    "roi_bot_right = (1040, 600)\n",
    "\n",
    "# defining entry and exit line\n",
    "entry_y = 430 # entering towards city centre\n",
    "exit_y = 350 # crossing into city centre\n",
    "\n",
    "# storing tracked cars\n",
    "tracked_cars = {}\n",
    "car_count = 0\n",
    "\n",
    "capture = capture1\n",
    "\n",
    "while True:\n",
    "    check, img = capture.read()\n",
    "    if not check: break # stop if end of video\n",
    "        \n",
    "    # applying background subtraction\n",
    "    fg_mask = background_sub.apply(img)\n",
    "    # dilating white areas of detected object\n",
    "    fg_mask = cv2.dilate(fg_mask, None, 20)\n",
    "    # shrinking white areas in binary mask\n",
    "    fg_mask = cv2.erode(fg_mask, None, 15)\n",
    "\n",
    "    # applying thresholding to clean up noise\n",
    "    threshold_mask = cv2.threshold(fg_mask, 150, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    # applying ROI (main street)\n",
    "    roi = np.zeros_like(threshold_mask)\n",
    "    cv2.rectangle(roi, roi_top_left, roi_bot_right, 255, thickness = -1)\n",
    "    threshold_mask = cv2.bitwise_and(threshold_mask, roi)\n",
    "    \n",
    "    # finding contours to detect moving objects\n",
    "    contours = cv2.findContours(threshold_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    \n",
    "    # storing bounding boxes of cars\n",
    "    curr_cars = []\n",
    "    \n",
    "    for c in contours:\n",
    "        # drawing bounding box around detected cars\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        # filtering out human shapes or small contours\n",
    "        if (h/w > 1.3) | (cv2.contourArea(c) < 1100): continue\n",
    "            \n",
    "        # getting car's center\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        \n",
    "        curr_cars.append((center_x, center_y, x, y, x + w, y + h))\n",
    "    \n",
    "    # tracking movement of cars across frames\n",
    "    new_tracked_cars = {}\n",
    "    \n",
    "    for car in curr_cars:\n",
    "        center_x, center_y, x1, y1, x2, y2 = car\n",
    "        \n",
    "        matched = False\n",
    "        for car_id, (prev_x, prev_y) in tracked_cars.items():\n",
    "            # checking for distance change\n",
    "            if abs(center_x - prev_x) < 50 and abs(center_y - prev_y) < 50 and abs(center_x - prev_x) > 5:\n",
    "                new_tracked_cars[car_id] = (center_x, center_y)\n",
    "                \n",
    "                # counting cars if it crosses from entry to exit\n",
    "                if prev_y >= entry_y and center_y < entry_y:\n",
    "                    car_count += 1\n",
    "                    print(f\"Car detected, Total: {car_count}\")\n",
    "                    \n",
    "                matched = True\n",
    "                break\n",
    "                \n",
    "        # assigning new ID to newly detected cars\n",
    "        if not matched:\n",
    "            new_tracked_cars[len(tracked_cars) + 1] = (center_x, center_y)\n",
    "    \n",
    "    tracked_cars = new_tracked_cars # updating car tracking\n",
    "    # draw entry and exit lines\n",
    "    cv2.line(img, (0, entry_y), (img.shape[1], entry_y), (255, 0, 0), 2)\n",
    "    cv2.line(img, (0, exit_y), (img.shape[1], exit_y), (0, 0, 255), 2)\n",
    "    \n",
    "    # drawing bounding box on detected cars\n",
    "    for car in curr_cars:\n",
    "        _, _, x1, y1, x2, y2 = car\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        \n",
    "    # displaying car count\n",
    "    cv2.putText(img, f\"Cars counted: {car_count}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "    # displaying the results\n",
    "    cv2.imshow(\"Traffic Video\", img)\n",
    "    \n",
    "    # exiting the loop\n",
    "    key = cv2.waitKey(1)\n",
    "    # using \"q\" key to exit\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# after the loop, release the video object\n",
    "capture.release()\n",
    "# destroy all windows\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
