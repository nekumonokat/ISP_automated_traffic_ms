{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65001823",
   "metadata": {},
   "source": [
    "# Ex 1.2 Counting Cars\n",
    "This task focuses on developing a computer vision application for counting the number of cars going from the city's downtown to the city centre in peak hours. It will be a progression to task 1.1 which uses the OpenCV library, and is based on frame differencing and background subtraction techniques. The project focuses on detecting cars that are in the \"Main street\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6074c8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48a665",
   "metadata": {},
   "source": [
    "The code will follow task 1.1's algorithm, tweaked to count cars.<br>The background subtractor MOG2 will be used with the same parameters as task 1.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9756ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully opened video 1.\n",
      "Successfully opened video 2.\n"
     ]
    }
   ],
   "source": [
    "# creating an instance of Gaussian Mixture-based background subtraction\n",
    "background_sub = cv2.createBackgroundSubtractorMOG2( history = 500,\n",
    "                                                     varThreshold = 50,\n",
    "                                                     detectShadows = True )\n",
    "\n",
    "# loading the video file\n",
    "vid_path1, vid_path2 = \"media/Traffic_Laramie_1.mp4\", \"media/Traffic_Laramie_2.mp4\"\n",
    "capture1 = cv2.VideoCapture(vid_path1)\n",
    "capture2 = cv2.VideoCapture(vid_path2)\n",
    "\n",
    "# checking if video 1 is opened successfully\n",
    "if not capture1.isOpened(): print(\"Error: Could not open video 1.\")\n",
    "else: print(\"Successfully opened video 1.\")\n",
    "# checking if video 2 is opened successfully\n",
    "if not capture2.isOpened(): print(\"Error: Could not open video 2.\")\n",
    "else: print(\"Successfully opened video 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8647a819",
   "metadata": {},
   "source": [
    "The algorithm detects and counts vehicles moving towards the city center. The Region of Interest (ROI) is applied to focus detection on the main street. ```cv2.dilate()``` and ```cv2.erode()``` are used to ensure that the detected vehicles are not fragmented whilst removing noise.\n",
    "\n",
    "Detected objects are processed using contour analysis, and non-vehicle objects are filtered out based on the aspect ratio and contour area. Vehicles are tracked across frames using its bounding box to ensure that it is only counted once when moving towards the city center.\n",
    "\n",
    "The algorithm uses real-time tracking and calculates the number of vehicles per minute by maintaining a history of bounding boxes across frames. Cars are only counted when they cross ```xThreshold = 200``` while moving from right to left. This movement also has to be tracked for 8 frames (```numOfFramesThreshold```) to avoid duplicated counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8679d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining main street region of interest (ROI)\n",
    "roi_top_left = (0, 250)\n",
    "roi_bot_right = (1040, 600)\n",
    "\n",
    "# defining entry and exit line\n",
    "entry_y = 450 # entering towards city centre\n",
    "exit_y = 330 # crossing into city centre\n",
    "\n",
    "# storing tracked cars\n",
    "prevBBoxes = []\n",
    "cars_per_min = 0 # number of cars per minute\n",
    "start_time = datetime.now() # getting current time\n",
    "v_counter = 0 # number of vehicles counted\n",
    "\n",
    "capture = capture2\n",
    "fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# defining movement tracking threshold\n",
    "deltaPosX, deltaPosY = 20, 20 # bounding box movement tolerance\n",
    "deltaSizeW, deltaSizeH = 20, 20 # bounding box size tolerance\n",
    "xThreshold = 200 # check when car moves left past this x-val\n",
    "numOfFramesThreshold = 8 # number of frames the car must be tracked for\n",
    "\n",
    "# tracking bounding box movement\n",
    "class bboxMovements:\n",
    "    def __init__(self, x, y, w, h):\n",
    "        self.x, self.y, self.w, self.h = x, y, w, h\n",
    "        self.direction = \"\"\n",
    "        self.isCounted = False\n",
    "        self.numOfFramesTracked = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13cdd993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Cars Counted: 5\n",
      "Cars per minute: 7.49\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    check, img = capture.read()\n",
    "    if not check: break # stop if end of video\n",
    "        \n",
    "    # applying background subtraction\n",
    "    fg_mask = background_sub.apply(img)\n",
    "    # dilating white areas of detected object\n",
    "    fg_mask = cv2.dilate(fg_mask, None, 20)\n",
    "    # shrinking white areas in binary mask\n",
    "    fg_mask = cv2.erode(fg_mask, None, 15)\n",
    "\n",
    "    # applying thresholding to clean up noise\n",
    "    threshold_mask = cv2.threshold(fg_mask, 150, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    # applying ROI (main street)\n",
    "    roi = np.zeros_like(threshold_mask)\n",
    "    cv2.rectangle(roi, roi_top_left, roi_bot_right, 255, thickness = -1)\n",
    "    threshold_mask = cv2.bitwise_and(threshold_mask, roi)\n",
    "    \n",
    "    # finding contours to detect moving objects\n",
    "    contours = cv2.findContours(threshold_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    \n",
    "    # storing bounding boxes of cars\n",
    "    currBboxes = []\n",
    "    \n",
    "    for c in contours:\n",
    "        # drawing bounding box around detected cars\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        # filtering out human shapes or small contours\n",
    "        if (h/w > 1.3) or (cv2.contourArea(c) < 1100): continue\n",
    "        currBboxes.append(bboxMovements(x, y, w, h))\n",
    "        # creating bounding box tracking object\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "    # matching prev bounding boxes to curr ones\n",
    "    for currBbox in currBboxes:\n",
    "        found = False\n",
    "        for prevBbox in prevBBoxes:\n",
    "            # calculating movement difference\n",
    "            deltaX = currBbox.x - prevBbox.x\n",
    "            deltaY = currBbox.y - prevBbox.y\n",
    "            deltaW = currBbox.w - prevBbox.w\n",
    "            deltaH = currBbox.h - prevBbox.h\n",
    "            \n",
    "            # if bounding box too far, it's a different car\n",
    "            if (abs(deltaX) > deltaPosX) | (abs(deltaY) > deltaPosY) |\\\n",
    "               (abs(deltaW) > deltaSizeW) | (abs(deltaH) > deltaSizeH): continue\n",
    "                \n",
    "            # match found, updating tracking info\n",
    "            found = True\n",
    "            \n",
    "            # labelling the box, showing direction and the number of frames\n",
    "            cv2.putText(img, f\"direction: {prevBbox.direction}, frames: {prevBbox.numOfFramesTracked}\",\n",
    "                       (currBbox.x, currBbox.y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            # calculating direction on X\n",
    "            if deltaX < 0:\n",
    "                currBbox.direction = \"left\"\n",
    "                currBbox.numOfFramesTracked = prevBbox.numOfFramesTracked + 1\n",
    "            elif deltaX > 0: currBbox.direction = \"right\"\n",
    "            else: currBbox.direction = \"\"\n",
    "                \n",
    "            # keeps track of counted bounding boxes from frame to frame\n",
    "            currBbox.isCounted = prevBbox.isCounted\n",
    "            \n",
    "            # counting cars when they leave frame to the left\n",
    "            if (currBbox.x < xThreshold) and (currBbox.numOfFramesTracked > numOfFramesThreshold) \\\n",
    "               and (currBbox.direction == \"left\") and (currBbox.isCounted == False):\n",
    "                v_counter += 1\n",
    "                currBbox.isCounted = True\n",
    "                \n",
    "        # if prev bounding box is found, continue\n",
    "        if found: continue\n",
    "            \n",
    "    # updating bounding boxes for next frame\n",
    "    prevBBoxes = currBboxes\n",
    "    # calculating time from beginning of vid to current frame\n",
    "    delta_time = datetime.now() - start_time\n",
    "    # getting number of seconds from beginning\n",
    "    seconds = delta_time.total_seconds()\n",
    "    # calculating number of cars detected per minute\n",
    "    cars_per_min = v_counter * 60 / seconds\n",
    "    \n",
    "    # draw entry and exit lines\n",
    "    cv2.line(img, (0, entry_y), (img.shape[1], entry_y), (255, 0, 0), 2)\n",
    "    cv2.line(img, (0, exit_y), (img.shape[1], exit_y), (0, 0, 255), 2)\n",
    "    \n",
    "    # displaying car count\n",
    "    cv2.putText(img, f\"Total Cars: {v_counter} in {int(seconds)}s - ({cars_per_min:.2f} cars/min)\",\n",
    "                (50, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "    \n",
    "    # displaying the results\n",
    "    cv2.imshow(\"Traffic Video\", img)\n",
    "    \n",
    "    # exiting the loop\n",
    "    key = cv2.waitKey(1)\n",
    "    # using \"q\" key to exit\n",
    "    if key == ord(\"q\"): break\n",
    "\n",
    "print(f\"Total Cars Counted: {v_counter}\")\n",
    "print(f\"Cars per minute: {cars_per_min:.2f}\")\n",
    "capture.release() # after the loop, release the video object\n",
    "cv2.destroyAllWindows() # destroy all windows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
